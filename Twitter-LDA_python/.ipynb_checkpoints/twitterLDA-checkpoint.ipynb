{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals  # noqa\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from user import user\n",
    "from Model import Model\n",
    "import Stopwords\n",
    " \n",
    "    \n",
    "class TwitterLDAmain:\n",
    "    \n",
    "    def __init__(self, mon, data_dir = \"/data\"):\n",
    "        self.base = os.getcwd() + data_dir\n",
    "        self.name = \"test\"\n",
    "        self.mon = mon\n",
    "        self.filelist = self.base + \"/files/\" + self.mon + \"_files.txt\"\n",
    "        self.dataDir = self.base + \"/Data4Model/\" + self.name + \"/\"\n",
    "        self.dataDir = self.base + \"/Data4Model/\" + self.name + \"/\"+ self.mon +\"/\"\n",
    "        self.outputDir = self.base + \"/ModelRes/\" + self.name + \"/\"+ self.mon +\"/\"\n",
    "        self.modelParas = self.base + \"/modelParameters-\" + self.name + \".txt\"\n",
    "        self.stopfile = self.base + \"/stoplist.txt\"\n",
    "        self.modelSettings = {}\n",
    "\n",
    "\n",
    "    def getModelPara(self, modelParas, modelSettings): \n",
    "        \n",
    "        modelSettings['topics'] = 40\n",
    "        modelSettings['alpha_g'] = 1.25\n",
    "        modelSettings[\"beta_word\"] = 0.01\n",
    "        modelSettings[\"beta_b\"] = 0.01\n",
    "        modelSettings[\"gamma\"] = 20\n",
    "        modelSettings[\"iteration\"] = 20                     \n",
    "\n",
    "        with open(modelParas, 'r', encoding='utf-8') as f:\n",
    "            inputlines = f.read().splitlines()\n",
    "\n",
    "        for item in inputlines:\n",
    "            x = item.split(\":\")\n",
    "            x = [x[0].strip(), x[1].strip()]\n",
    "            if(x[1] and (x[0] in modelSettings)):\n",
    "                modelSettings[x[0]] = float(x[1])\n",
    "                \n",
    "                \n",
    "    def errprint(self, *args, **kwargs):\n",
    "        print(*args, file=sys.stderr, **kwargs)\n",
    "        \n",
    "                \n",
    "    def main(self):\n",
    "        \n",
    "        # 1. get model parameters\n",
    "        \n",
    "        self.getModelPara(self.modelParas, self.modelSettings)\n",
    "        A_all = self.modelSettings['topics']\n",
    "        alpha_g = self.modelSettings['alpha_g']\n",
    "        beta_word = self.modelSettings['beta_word']\n",
    "        beta_b = self.modelSettings['beta_b']\n",
    "        gamma = self.modelSettings['gamma']\n",
    "        nIter = self.modelSettings['iteration']\n",
    "        \n",
    "        self.errprint(\"Topics:\" + str(A_all) + \", alpha_g:\" + str(alpha_g) + \", beta_word:\" + str(beta_word) + \", beta_b:\" + str(beta_b) + \", gamma:\" + str(gamma) + \", iteration:\" + str(nIter))\n",
    "        self.modelSettings.clear()\n",
    "        \n",
    "        \n",
    "        Stopwords.Stopwords()\n",
    "        Stopwords.addStopfile(self.stopfile)\n",
    "        sw = Stopwords.stopwords_list\n",
    "        \n",
    "        outputTopicwordCnt = 30\n",
    "        outputBackgroundwordCnt = 50\n",
    "\n",
    "        outputWordsInTopics = self.outputDir + \"WordsInTopics.txt\"\n",
    "        outputBackgroundWordsDistribution = self.outputDir + \"BackgroundWordsDistribution.txt\"\n",
    "        outputTextWithLabel = self.outputDir + \"/TextWithLabel/\"\n",
    "\n",
    "#         outputTextWithLabelfile = open(outputTextWithLabel, 'w', encoding='utf-8')\n",
    "        \n",
    "        if not os.path.exists(outputTextWithLabel):\n",
    "            os.makedirs(outputTextWithLabel)\n",
    "        \n",
    "        # 2. get documents (users)\n",
    "        # HashMap<String, Integer> wordMap = new HashMap<String, Integer>();\n",
    "        # ArrayList<user> users = new ArrayList<user>();\n",
    "        # ArrayList<String> uniWordMap = new ArrayList<String>();\n",
    "        \n",
    "        wordMap = {}\n",
    "        uniWordMap = []\n",
    "        users = []\n",
    "\n",
    "        with open(self.filelist, 'r', encoding='utf-8') as f:\n",
    "            files = f.read().splitlines()\n",
    "            \n",
    "        \n",
    "            \n",
    "        for file in files:\n",
    "            tweetuser = user(self.dataDir + file, file, wordMap, uniWordMap)\n",
    "            tweetuser.user()\n",
    "            wordMap = tweetuser.wordMap\n",
    "            uniWordMap = tweetuser.uniWordMap\n",
    "            users.append(tweetuser)\n",
    "            \n",
    "        if (len(uniWordMap) != len(wordMap)):\n",
    "            print(len(wordMap))\n",
    "            print(len(uniWordMap))\n",
    "            self.errprint(\"uniqword size is not the same as the hashmap size!\")\n",
    "            sys.exit(0)\n",
    "            \n",
    "        # output wordMap and itemMap\n",
    "        with open(self.outputDir + \"wordMap.txt\", 'w', encoding='utf-8') as f:\n",
    "            for k, v in wordMap.items():\n",
    "                f.write(str(k) + '\\t'+ str(v) + '\\n')\n",
    "                \n",
    "        with open(self.outputDir + \"uniWordMap.txt\", 'w', encoding='utf-8') as f:\n",
    "            for k in uniWordMap:\n",
    "                f.write(str(k)+ '\\n')\n",
    "                \n",
    "        uniWordMapSize = len(uniWordMap)\n",
    "        wordMap.clear()\n",
    "        uniWordMap.clear()\n",
    "\n",
    "        # 3. run the model\n",
    "        model = Model(A_all, len(users), uniWordMapSize, nIter, alpha_g, beta_word, beta_b, gamma)\n",
    "        model.initialize(users)\n",
    "        model.estimate(users, nIter)\n",
    "        \n",
    "        # 4. output model results\n",
    "        print(\"Record Topic Distributions/Counts\")\n",
    "        model.outputTopicDistributionOnUsers(self.outputDir, users)\n",
    "        print(\"read uniwordmap\")\n",
    "        \n",
    "        with open(self.outputDir + \"uniWordMap.txt\", 'r', encoding='utf-8') as f:\n",
    "            uniWordMap = f.read().splitlines()\n",
    "        \n",
    "        try:\n",
    "            model.outputTextWithLabel(outputTextWithLabel, users, uniWordMap)\n",
    "        except:\n",
    "            print(\"An exception occurred in outputTextWithLabel: \", sys.exc_info()[0])\n",
    "            \n",
    "        print(\"write text with labels done\")\n",
    "        # model.outputTopicCountOnTime(outputTopicsCountOnTime)\n",
    "        users.clear()\n",
    "\n",
    "        try:\n",
    "            model.outputWordsInTopics(outputWordsInTopics, uniWordMap, outputTopicwordCnt)\n",
    "        except:\n",
    "            print(\"An exception occurred in outputWordsInTopics: \", sys.exc_info()[0])\n",
    "\n",
    "        print(\"write topics with keywords done\")\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            model.outputBackgroundWordsDistribution(outputBackgroundWordsDistribution, uniWordMap, outputBackgroundwordCnt)\n",
    "        except:\n",
    "            print(\"An exception occurred in outputBackgroundWordsDistribution: \", sys.exc_info()[0])\n",
    "            \n",
    "        print(\"Record Background done\")\n",
    "        print(\"Final Done\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Topics:20.0, alpha_g:0.5, beta_word:0.01, beta_b:0.01, gamma:20.0, iteration:10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20113\n",
      "initializing...\n",
      "Intialize Done\n",
      "iteration 1 ...\n",
      "iteration 2 ...\n",
      "iteration 3 ...\n",
      "iteration 4 ...\n",
      "iteration 5 ...\n",
      "iteration 6 ...\n",
      "iteration 7 ...\n",
      "iteration 8 ...\n",
      "iteration 9 ...\n",
      "iteration 10 ...\n",
      "Record Topic Distributions/Counts\n",
      "read uniwordmap\n",
      "write text with labels done\n",
      "write topics with keywords done\n",
      "Record Background done\n",
      "Final Done\n"
     ]
    }
   ],
   "source": [
    "twitterLDA = TwitterLDAmain('Jul')\n",
    "twitterLDA.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topics': 40, 'alpha_g': 1.25, 'beta_word': 0.01, 'beta_b': 0.01, 'gamma': 20, 'iteration': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topics': 20.0,\n",
       " 'alpha_g': 0.5,\n",
       " 'beta_word': 0.01,\n",
       " 'beta_b': 0.01,\n",
       " 'gamma': 20.0,\n",
       " 'iteration': 100.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = os.getcwd() + \"/data\"\n",
    "name = \"test\"\n",
    "modelParas = base + \"/modelParameters-\" + name + \".txt\"\n",
    "modelSettings = {}\n",
    "getModelPara(modelParas, modelSettings)\n",
    "modelSettings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(5, 7, 6, 3, 2.3, 0.05, 0.01, 0.47)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "\n",
    "AA = [1,5,6,7,8]\n",
    "\n",
    "rn = 5\n",
    "\n",
    "for i in range(rn):\n",
    "    test.append(AA[i])\n",
    "    print(test[i])\n",
    "    \n",
    "theta_general = [0]*5 #[ [ 0 for i in range(5) ] for j in range(4) ]\n",
    "# x = theta_general[0][2]\n",
    "theta_general[2] += 2\n",
    "theta_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaya\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "if (2 > 1):\n",
    "    buff = True\n",
    "else:\n",
    "    buff = False\n",
    "\n",
    "if (buff):\n",
    "    print(\"yaya\")\n",
    "    \n",
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "C_word = [ [ 0 for i in range(4) ] for j in range(5) ]\n",
    "print(C_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.float_info.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
